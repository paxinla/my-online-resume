###  【Jun 2013 - Aug 2015】 A Business Data Loading Platform for a commercial bank

+ Orchestration | Massive Data ETL

```
This project is a platform for implementing ETL processes and scheduling for various characteristic application systems of the Shenzhen Branch of a large commercial bank. It customizes, processes and delivers data from heterogeneous data sources to the online library of the business system according to the needs of various downstream business systems.
``` 

My responsibilities in this project included:

1. Responsible for maintaining and developing the orchestrating and core job procedures of the platform.
2. Design and maintain the ETL processes for data files transferred from the head office and data in the specialized system database on the platform. Handle any platform failures promptly.
3. Customize ETL processes according to new requirements raised by users of different specialized application systems, monitor and ensure the successful completion of daily batch processing.
4. Assist in retrieving historical data for specialized application system users as required.

The project involves multiple heterogeneous data sources belonging to other organizations' systems, and the destination is the application-level data marts and OLTP databases of various departmental specialized business systems. There are certain requirements for the execution efficiency of batch jobs. After me taking over the project, I completed the transformation of most of the existing historical job programs, improving their fault tolerance and the platform's ability to automatically handle errors.

For example, the platform has a source table with approximately 40 million account records, which serves as the data source for many downstream target systems. On quarterly interest settlement days, the significant increase in data volume often led to excessively long runtimes and frequent failures of the loading job (in merge mode), requiring manual on-site monitoring and intervention. After me taking over the project, I optimized the ETL process for this table by automatically splitting and slicing the source data files, analyzing incremental changes, and merging them into the existing snapshot table. This improvement enhanced the overall data loading efficiency and automation level, ensuring that the job runs stably and normally both on interest settlement days and regular days.

