###  【2015.11 - 2018.11】  求职就业领域的数据仓库 项目 

+ 数据仓库 | Hadoop

```  
该项目为公司的数据基础设施之一，为 AI 算法团队的数据科学家和数据挖掘工程师提供稳定质量的数据支持及海量数据处理的技术支持。
``` 

我在这个项目中负责的工作有：

1. 负责大数据平台的核心数据仓库和数据集市的建设，包括开发规范、维度建模、质量指标规范。
2. 带领团队成员处理数据，包括数据清洗、量化、集成、存储等。
3. 规划大数据平台的技术方案并实施。
4. 为 AI 算法团队提供处理海量数据的技术支持。


该项目属于公司基础数据设施的重要组成部分，集成了数据采集团队获得的多年求职就业领域的数据。主要用来为公司 AI 算法团队的数据科学家和数据挖掘工程师提供数据集，并将他们的产出模型应用到存量数据(约30TB)上获得结果，以供公司的数据产品使用。并周期性批量生成大专院校的就业统计数据报告，供公司的拳头产品“XX志愿”使用。

在这个项目中，我带领数据开发团队，根据公司数据战略的目标及就业领域的数据的特点，设计并落地了基于 CDH 和 PostgreSQL 来构建数据仓库的方案。综合使用了 Pentaho Data Integration 、DataX 、Hive 、MapReduce 、Spark 等组件构建了 ETL 及 data pipeline ，构建基于 Apache Airflow 的作业调度系统。用集中的自动化调度及监控替代了公司过去遗留的分散的应激式数据转换作业。比如，原先一个需运行耗时约一周的全量计算作业，在新平台上的耗时缩短到约1.5天。

